{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9edc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import math\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d245447",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('test_dataset/images/25.jpg')\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imutils.resize(image, width=500)\n",
    "img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the original image\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10,7))\n",
    "ax[0,0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "ax[0,0].set_title('Original Image')\n",
    "\n",
    "# RGB to Gray scale conversion\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "ax[0,1].imshow(gray, cmap='gray')\n",
    "ax[0,1].set_title('Grayscale Conversion')\n",
    "\n",
    "# Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "ax[1,0].imshow(gray, cmap='gray')\n",
    "ax[1,0].set_title('Bilateral Filter')\n",
    "\n",
    "# Find Edges of the grayscale image\n",
    "edged = cv2.Canny(gray, 170, 200)\n",
    "ax[1,1].imshow(edged, cmap='gray')\n",
    "ax[1,1].set_title('Canny Edges')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "# Find contours based on Edges\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] #sort contours based on their area keeping minimum required area as '30' (anything smaller than this will not be considered)\n",
    "NumberPlateCnt = None #we currently have no Number plate contour\n",
    "\n",
    "# loop over our contours to find the best possible approximate contour of number plate\n",
    "count = 0\n",
    "for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:  # Select the contour with 4 corners\n",
    "            NumberPlateCnt = approx #This is our approx Number Plate Contour\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            ROI = img[y:y+h, x:x+w]\n",
    "            break\n",
    "\n",
    "if NumberPlateCnt is not None:\n",
    "    # Drawing the selected contour on the original image\n",
    "    cv2.drawContours(image, [NumberPlateCnt], -1, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Detected license plate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f416737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bounding box and extract ROI\n",
    "plt.imshow(ROI)\n",
    "plt.title(\"Extracted license plate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdd30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NumberPlateCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55184804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance between (x1, y1) and (x2, y2)\n",
    "def dist(x1, x2, y1, y2):\n",
    "    return ((x1-x2)**2+(y1-y2)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e303de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=0\n",
    "m=0\n",
    "# To find the index of coordinate with maximum y-coordinate\n",
    "for i in range(4):\n",
    "    if NumberPlateCnt[i][0][1]>m:\n",
    "        idx=i\n",
    "        m=NumberPlateCnt[i][0][1]\n",
    "\n",
    "# Assign index to the previous coordinate\n",
    "if idx==0:\n",
    "    pin=3\n",
    "else:\n",
    "    pin=idx-1\n",
    "\n",
    "# Assign index to the next coordinate\n",
    "if idx==3:\n",
    "    nin=0\n",
    "else:\n",
    "    nin=idx+1\n",
    "\n",
    "# Find distances between the acquired coordinate and its previous and next coordinate\n",
    "p=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[pin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[pin][0][1])\n",
    "n=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[nin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[nin][0][1])\n",
    "\n",
    "# The coordinate that has more distance from the acquired coordinate is the required second bottom-most coordinate\n",
    "if p>n:\n",
    "    if NumberPlateCnt[pin][0][0]<NumberPlateCnt[idx][0][0]:\n",
    "        left=pin\n",
    "        right=idx\n",
    "    else:\n",
    "        left=idx\n",
    "        right=pin\n",
    "    d=p\n",
    "else:\n",
    "    if NumberPlateCnt[nin][0][0]<NumberPlateCnt[idx][0][0]:\n",
    "        left=nin\n",
    "        right=idx\n",
    "    else:\n",
    "        left=idx\n",
    "        right=nin\n",
    "    d=n\n",
    "print(left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db30f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_x=NumberPlateCnt[left][0][0]\n",
    "left_y=NumberPlateCnt[left][0][1]\n",
    "right_x=NumberPlateCnt[right][0][0]\n",
    "right_y=NumberPlateCnt[right][0][1]\n",
    "print(left_x, left_y, right_x, right_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94258684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the angle of rotation by calculating sin of theta\n",
    "opp=right_y-left_y\n",
    "hyp=((left_x-right_x)**2+(left_y-right_y)**2)**0.5\n",
    "sin=opp/hyp\n",
    "theta=math.asin(sin)*57.2958\n",
    "\n",
    "# Rotate the image according to the angle of rotation obtained\n",
    "image_center = tuple(np.array(ROI.shape[1::-1]) / 2)\n",
    "rot_mat = cv2.getRotationMatrix2D(image_center, theta, 1.0)\n",
    "result = cv2.warpAffine(ROI, rot_mat, ROI.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# The image can be cropped after rotation( since rotated image takes much more height)\n",
    "if opp>0:\n",
    "    h=result.shape[0]-opp//2\n",
    "else:\n",
    "    h=result.shape[0]+opp//2\n",
    "\n",
    "result=result[0:h, :]\n",
    "plt.imshow(result)\n",
    "plt.title(\"Plate obtained after rotation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(dimensions, img) :\n",
    "\n",
    "    # Find all contours in the image\n",
    "    cntrs, _ = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Retrieve potential dimensions\n",
    "    lower_width = dimensions[0]\n",
    "    upper_width = dimensions[1]\n",
    "    lower_height = dimensions[2]\n",
    "    upper_height = dimensions[3]\n",
    "    \n",
    "    # Check largest 5 or  15 contours for license plate or character respectively\n",
    "    cntrs = sorted(cntrs, key=cv2.contourArea, reverse=True)[:15]\n",
    "    \n",
    "    ii = cv2.imread('contour.jpg')\n",
    "    \n",
    "    x_cntr_list = []\n",
    "    target_contours = []\n",
    "    img_res = []\n",
    "    for cntr in cntrs :\n",
    "        # detects contour in binary image and returns the coordinates of rectangle enclosing it\n",
    "        intX, intY, intWidth, intHeight = cv2.boundingRect(cntr)\n",
    "              # checking the dimensions of the contour to filter out the characters by contour's size\n",
    "        if intWidth > lower_width and intWidth < upper_width and intHeight > lower_height and intHeight < upper_height :\n",
    "            x_cntr_list.append(intX) #stores the x coordinate of the character's contour, to used later for indexing the contours\n",
    "\n",
    "            char_copy = np.zeros((44,24))\n",
    "            # extracting each character using the enclosing rectangle's coordinates.\n",
    "            char = img[intY:intY+intHeight, intX:intX+intWidth]\n",
    "            char = cv2.resize(char, (20, 40))\n",
    "            \n",
    "            cv2.rectangle(ii, (intX,intY), (intWidth+intX, intY+intHeight), (50,21,200), 2)\n",
    "            plt.imshow(ii, cmap='gray')\n",
    "            plt.title('Predict Segments')\n",
    "\n",
    "            # Make result formatted for classification: invert colors\n",
    "            char = cv2.subtract(255, char)\n",
    "\n",
    "            # Resize the image to 24x44 with black border\n",
    "            char_copy[2:42, 2:22] = char\n",
    "            char_copy[0:2, :] = 0\n",
    "            char_copy[:, 0:2] = 0\n",
    "            char_copy[42:44, :] = 0\n",
    "            char_copy[:, 22:24] = 0\n",
    "\n",
    "            img_res.append(char_copy) # List that stores the character's binary image (unsorted)\n",
    "            \n",
    "    # Return characters on ascending order with respect to the x-coordinate (most-left character first)\n",
    "            \n",
    "    plt.show()\n",
    "    # arbitrary function that stores sorted list of character indeces\n",
    "    indices = sorted(range(len(x_cntr_list)), key=lambda k: x_cntr_list[k])\n",
    "    img_res_copy = []\n",
    "     for idx in indices:\n",
    "        img_res_copy.append(img_res[idx])# stores character images according to their index\n",
    "    img_res = np.array(img_res_copy)\n",
    "\n",
    "    return img_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3417a9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find characters in the resulting images\n",
    "def segment_characters(image) :\n",
    "\n",
    "    # Preprocess cropped license plate image\n",
    "    img_lp = cv2.resize(image, (333, 75))\n",
    "    img_gray_lp = cv2.cvtColor(img_lp, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_binary_lp = cv2.threshold(img_gray_lp, 200, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    img_binary_lp = cv2.erode(img_binary_lp, (3,3))\n",
    "    img_binary_lp = cv2.dilate(img_binary_lp, (3,3))\n",
    "\n",
    "    LP_WIDTH = img_binary_lp.shape[0]\n",
    "    LP_HEIGHT = img_binary_lp.shape[1]\n",
    "\n",
    "    # Make borders white\n",
    "    img_binary_lp[0:3,:] = 255\n",
    "    img_binary_lp[:,0:3] = 255\n",
    "    img_binary_lp[72:75,:] = 255\n",
    "    img_binary_lp[:,330:333] = 255\n",
    "\n",
    "    # Estimations of character contours sizes of cropped license plates\n",
    "    dimensions = [LP_WIDTH/6,\n",
    "                       LP_WIDTH/2,\n",
    "                       LP_HEIGHT/10,\n",
    "                       2*LP_HEIGHT/3]\n",
    "    plt.imshow(img_binary_lp, cmap='gray')\n",
    "    plt.title('Contour')\n",
    "    plt.show()\n",
    "    cv2.imwrite('contour.jpg',img_binary_lp)\n",
    "\n",
    "    # Get contours within cropped license plate\n",
    "    char_list = find_contours(dimensions, img_binary_lp)\n",
    "\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c30dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "char=segment_characters(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d938e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(char)):\n",
    "    plt.subplot(1, len(char), i+1)\n",
    "    plt.imshow(char[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d00b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, width_shift_range=0.1, height_shift_range=0.1)\n",
    "path = 'data'\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        path+'/train',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28\n",
    "        batch_size=1,\n",
    "        class_mode='sparse')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        path+'/val',  # this is the target directory\n",
    "        target_size=(28,28),  # all images will be resized to 28x28 batch_size=1,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c280506",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.Adam(lr=0.0001), metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "result = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch = train_generator.samples // batch_size,\n",
    "      validation_data = validation_generator, \n",
    "      epochs = 25, verbose=1, callbacks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02204aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,5))\n",
    "grid=gridspec.GridSpec(ncols=2,nrows=1,figure=fig)\n",
    "fig.add_subplot(grid[0])\n",
    "plt.plot(result.history['accuracy'], label='training accuracy')\n",
    "plt.plot(result.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(grid[1])\n",
    "plt.plot(result.history['loss'], label='training loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a141e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance\n",
    "loaded_model = Sequential()\n",
    "loaded_model.add(Conv2D(16, (22,22), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "loaded_model.add(Conv2D(32, (16,16), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "loaded_model.add(Conv2D(64, (8,8), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "loaded_model.add(Conv2D(64, (4,4), input_shape=(28, 28, 3), activation='relu', padding='same'))\n",
    "loaded_model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "loaded_model.add(Dropout(0.4))\n",
    "loaded_model.add(Flatten())\n",
    "loaded_model.add(Dense(128, activation='relu'))\n",
    "loaded_model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "# Restore the weights\n",
    "loaded_model.load_weights('checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2689e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the output\n",
    "def fix_dimension(img): \n",
    "    new_img = np.zeros((28,28,3))\n",
    "    for i in range(3):\n",
    "        new_img[:,:,i] = img\n",
    "        return new_img\n",
    "  \n",
    "def show_results():\n",
    "    dic = {}\n",
    "    characters = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    for i,c in enumerate(characters):\n",
    "        dic[i] = c\n",
    "\n",
    "    output = []\n",
    "    for i,ch in enumerate(char): #iterating over the characters\n",
    "        img_ = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "        img = fix_dimension(img_)\n",
    "        img = img.reshape(1,28,28,3) #preparing image for the model\n",
    "        y_ = loaded_model.predict_classes(img)[0] #predicting the class\n",
    "        character = dic[y_]\n",
    "        output.append(character) #storing the result in a list\n",
    "        \n",
    "    plate_number = ''.join(output)\n",
    "    \n",
    "    return plate_number\n",
    "\n",
    "print(show_results())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmented characters and their predicted value.\n",
    "plt.figure(figsize=(10,6))\n",
    "for i,ch in enumerate(char):\n",
    "    img = cv2.resize(ch, (28,28), interpolation=cv2.INTER_AREA)\n",
    "    plt.subplot(3,4,i+1)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title(f'predicted: {show_results()[i]}')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97044782",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_excel('test_dataset/labels.xlsx')\n",
    "labels['ID']=labels['ID'].map(str)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list=os.listdir(r\"test_dataset/images\")\n",
    "count=0\n",
    "for path in file_list:\n",
    "    no=path[:-4]\n",
    "    row=labels['NUMBER'].where(labels['ID'] == no).dropna().values[0]\n",
    "    image = cv2.imread('test_dataset/images/'+path)\n",
    "    # Resize the image - change width to 500\n",
    "    image = imutils.resize(image, width=500)\n",
    "    img=cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # RGB to Gray scale conversion\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise removal with iterative bilateral filter(removes noise while preserving edges)\n",
    "    gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "    # Find Edges of the grayscale image\n",
    "    edged = cv2.Canny(gray, 170, 200)\n",
    "\n",
    "    # Find contours based on Edges\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[0]\n",
    "    cnts=sorted(cnts, key = cv2.contourArea, reverse = True)[:30] #sort contours based on their area keeping minimum required area as '30' (anything smaller than this will not be considered)\n",
    "    NumberPlateCnt = None #we currently have no Number plate contour\n",
    "\n",
    "    # loop over our contours to find the best possible approximate contour of number plate\n",
    "    for c in cnts:\n",
    "            peri = cv2.arcLength(c, True)\n",
    "            approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "            if len(approx) == 4:  # Select the contour with 4 corners\n",
    "                NumberPlateCnt = approx #This is our approx Number Plate Contour\n",
    "                x,y,w,h = cv2.boundingRect(c)\n",
    "                ROI = img[y:y+h, x:x+w]\n",
    "                break\n",
    "\n",
    "    idx=0\n",
    "    m=0\n",
    "    if NumberPlateCnt is None:\n",
    "        continue\n",
    "    for i in range(4):\n",
    "        if NumberPlateCnt[i][0][1]>m:\n",
    "            idx=i\n",
    "            m=NumberPlateCnt[i][0][1]\n",
    "    if idx==0:\n",
    "        pin=3\n",
    "    else:\n",
    "        pin=idx-1\n",
    "    if idx==3:\n",
    "        nin=0\n",
    "    else:\n",
    "        nin=idx+1\n",
    "\n",
    "    p=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[pin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[pin][0][1])\n",
    "    n=dist(NumberPlateCnt[idx][0][0], NumberPlateCnt[nin][0][0], NumberPlateCnt[idx][0][1], NumberPlateCnt[nin][0][1])\n",
    "\n",
    "    if p>n:\n",
    "        if NumberPlateCnt[pin][0][0]<NumberPlateCnt[idx][0][0]:\n",
    "            left=pin\n",
    "            right=idx\n",
    "        else:\n",
    "            left=idx\n",
    "            right=pin\n",
    "              else:\n",
    "            left=idx\n",
    "            right=nin\n",
    "        d=n\n",
    "    left_x=NumberPlateCnt[left][0][0]\n",
    "    left_y=NumberPlateCnt[left][0][1]\n",
    "    right_x=NumberPlateCnt[right][0][0]\n",
    "    right_y=NumberPlateCnt[right][0][1]\n",
    "\n",
    "    opp=right_y-left_y\n",
    "    hyp=((left_x-right_x)**2+(left_y-right_y)**2)**0.5\n",
    "    sin=opp/hyp\n",
    "    theta=math.asin(sin)*57.2958\n",
    "\n",
    "    image_center = tuple(np.array(ROI.shape[1::-1]) / 2)\n",
    "    rot_mat = cv2.getRotationMatrix2D(image_center, theta, 1.0)\n",
    "    result = cv2.warpAffine(ROI, rot_mat, ROI.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    if opp>0:\n",
    "        h=result.shape[0]-opp//2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
